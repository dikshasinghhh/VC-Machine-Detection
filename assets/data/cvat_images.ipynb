{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# for zip file"
      ],
      "metadata": {
        "id": "L0V8okwcSERr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Set the path to the uploaded ZIP file\n",
        "zip_path = '/content/try-1.zip'  # Update this if your file has a different name\n",
        "extract_path = '/content/dataset'  # Destination folder\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Dataset extracted to {extract_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqdXP0yJoo3A",
        "outputId": "ad0c3362-4690-449b-f2ff-b97990c88a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this also for all frames"
      ],
      "metadata": {
        "id": "GtdEEpBcSAaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf6dtTfRhmno",
        "outputId": "7b2cd916-8394-4ce2-9173-e007b239d069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting frames...\n",
            "Done: 2391 frames extracted to /content/dataset/images/train\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "video_path = \"/content/VC Video.mp4\"  # <-- Replace with your actual video path\n",
        "output_dir = \"/content/dataset/images/train\"\n",
        "total_frames_expected = 2391  # frames 0 to 2390\n",
        "image_format = \"jpg\"\n",
        "\n",
        "# === CREATE OUTPUT FOLDER ===\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === READ VIDEO ===\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "if frame_count < total_frames_expected:\n",
        "    print(f\"Warning: video only has {frame_count} frames, expected {total_frames_expected}\")\n",
        "elif frame_count > total_frames_expected:\n",
        "    print(f\"Note: video has {frame_count} frames, but CVAT used only 2391 (0–2390)\")\n",
        "\n",
        "print(\"Extracting frames...\")\n",
        "\n",
        "frame_idx = 0\n",
        "while frame_idx < total_frames_expected:\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        print(f\"Error reading frame at index {frame_idx}\")\n",
        "        break\n",
        "    filename = f\"frame_{frame_idx:06d}.{image_format}\"  # ← MATCHING the annotation file names\n",
        "    cv2.imwrite(os.path.join(output_dir, filename), frame)\n",
        "    frame_idx += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Done: {frame_idx} frames extracted to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this for only labelled frames"
      ],
      "metadata": {
        "id": "ACDK5mw9RSl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "video_path = \"/content/VC Video.mp4\"  # Path to your video\n",
        "labels_dir = \"/content/dataset/labels/train\"  # Label files directory\n",
        "output_dir = \"/content/dataset/images/train\"  # Where to save extracted frames\n",
        "image_format = \"jpg\"\n",
        "\n",
        "# === COLLECT FRAME INDICES FROM LABEL FILES ===\n",
        "label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]\n",
        "frame_indices = sorted([\n",
        "    int(f.split('_')[1].split('.')[0]) for f in label_files\n",
        "])  # Extract frame numbers like 000117 → 117\n",
        "\n",
        "print(f\"{len(frame_indices)} labeled frames found (from {min(frame_indices)} to {max(frame_indices)}).\")\n",
        "\n",
        "# === CREATE OUTPUT FOLDER ===\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === READ VIDEO ===\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "print(\"Extracting only labeled frames...\")\n",
        "\n",
        "frame_pos = 0\n",
        "extracted = 0\n",
        "target_set = set(frame_indices)\n",
        "\n",
        "while frame_pos <= max(frame_indices):\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        print(f\"Error reading frame at index {frame_pos}\")\n",
        "        break\n",
        "\n",
        "    if frame_pos in target_set:\n",
        "        filename = f\"frame_{frame_pos:06d}.{image_format}\"\n",
        "        cv2.imwrite(os.path.join(output_dir, filename), frame)\n",
        "        extracted += 1\n",
        "\n",
        "    frame_pos += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Done: {extracted} labeled frames extracted to {output_dir}\")\n"
      ],
      "metadata": {
        "id": "4akypR3MRRq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this also only for labelled ones"
      ],
      "metadata": {
        "id": "AEI4Fg_qRZZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "image_dir = \"/content/dataset/images/train\"\n",
        "label_dir = \"/content/dataset/labels/train\"\n",
        "data_yaml_path = \"/content/dataset/data.yaml\"\n",
        "output_video_path = \"/content/output_annotated_video.mp4\"\n",
        "image_format = \"jpg\"\n",
        "fps = 30  # Set based on your original video\n",
        "\n",
        "# === LOAD CLASS NAMES FROM YAML ===\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "class_names = data['names']\n",
        "\n",
        "# === COLLECT IMAGE FILES ===\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(image_dir) if f.endswith(f\".{image_format}\")\n",
        "])\n",
        "\n",
        "if not image_files:\n",
        "    raise FileNotFoundError(\"No image files found in image_dir.\")\n",
        "\n",
        "# === PREPARE VIDEO WRITER ===\n",
        "first_frame = cv2.imread(os.path.join(image_dir, image_files[0]))\n",
        "frame_height, frame_width = first_frame.shape[:2]\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# === FUNCTION TO DRAW BBOXES ===\n",
        "def draw_annotations(image, label_path):\n",
        "    h, w = image.shape[:2]\n",
        "    if not os.path.exists(label_path):\n",
        "        return image  # No annotation\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls_id, x_c, y_c, box_w, box_h = map(float, parts)\n",
        "            x1 = int((x_c - box_w / 2) * w)\n",
        "            y1 = int((y_c - box_h / 2) * h)\n",
        "            x2 = int((x_c + box_w / 2) * w)\n",
        "            y2 = int((y_c + box_h / 2) * h)\n",
        "            cls_name = class_names[int(cls_id)]\n",
        "            color = (0, 255, 0)\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, cls_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    return image\n",
        "\n",
        "# === PROCESS AND SAVE VIDEO ===\n",
        "print(\"Rendering annotated video...\")\n",
        "\n",
        "for image_file in image_files:\n",
        "    frame_path = os.path.join(image_dir, image_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "    if frame is None:\n",
        "        print(f\"Warning: Could not read {frame_path}\")\n",
        "        continue\n",
        "\n",
        "    frame_id = os.path.splitext(image_file)[0]  # e.g., \"frame_000117\"\n",
        "    label_path = os.path.join(label_dir, f\"{frame_id}.txt\")\n",
        "    annotated = draw_annotations(frame, label_path)\n",
        "    out.write(annotated)\n",
        "\n",
        "out.release()\n",
        "print(f\"✅ Annotated video saved at: {output_video_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kjC7sr8QtCl",
        "outputId": "aafca8ee-db0e-4fd0-f8f7-b0bc2630d4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering annotated video...\n",
            "✅ Annotated video saved at: /content/output_annotated_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this for all frames\n"
      ],
      "metadata": {
        "id": "Khfrm6JgRc3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "image_dir = \"/content/dataset/images/train\"\n",
        "label_dir = \"/content/dataset/labels/train\"\n",
        "data_yaml_path = \"/content/dataset/data.yaml\"\n",
        "output_video_path = \"/content/output_annotated_video.mp4\"\n",
        "image_format = \"jpg\"\n",
        "fps = 30  # Adjust to match your original video\n",
        "total_frames = 2391  # 0 to 2390\n",
        "\n",
        "# === LOAD CLASS NAMES FROM YAML ===\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "class_names = data['names']\n",
        "\n",
        "# === PREPARE VIDEO WRITER ===\n",
        "first_frame_path = os.path.join(image_dir, f\"frame_{0:06d}.{image_format}\")\n",
        "first_frame = cv2.imread(first_frame_path)\n",
        "if first_frame is None:\n",
        "    raise FileNotFoundError(f\"First frame not found at {first_frame_path}\")\n",
        "frame_height, frame_width = first_frame.shape[:2]\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# === FUNCTION TO DRAW BBOXES ===\n",
        "def draw_annotations(image, label_path):\n",
        "    h, w = image.shape[:2]\n",
        "    if not os.path.exists(label_path):\n",
        "        return image  # No annotation\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue  # Skip invalid lines\n",
        "            cls_id, x_c, y_c, box_w, box_h = map(float, parts)\n",
        "            x1 = int((x_c - box_w / 2) * w)\n",
        "            y1 = int((y_c - box_h / 2) * h)\n",
        "            x2 = int((x_c + box_w / 2) * w)\n",
        "            y2 = int((y_c + box_h / 2) * h)\n",
        "            cls_name = class_names[int(cls_id)]\n",
        "            color = (0, 255, 0)\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, cls_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    return image\n",
        "\n",
        "# === PROCESS AND SAVE VIDEO ===\n",
        "print(\"Rendering annotated video...\")\n",
        "for i in range(total_frames):\n",
        "    img_path = os.path.join(image_dir, f\"frame_{i:06d}.{image_format}\")\n",
        "    label_path = os.path.join(label_dir, f\"frame_{i:06d}.txt\")\n",
        "    frame = cv2.imread(img_path)\n",
        "    if frame is None:\n",
        "        print(f\"Missing frame: {img_path}\")\n",
        "        continue\n",
        "    annotated = draw_annotations(frame, label_path)\n",
        "    out.write(annotated)\n",
        "\n",
        "out.release()\n",
        "print(f\"✅ Annotated video saved at: {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "cS8_xURrRhM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This for downloading that file"
      ],
      "metadata": {
        "id": "V11CSjixRiOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Zip the dataset folder (recursively)\n",
        "shutil.make_archive('/content/dataset_new', 'zip', '/content/dataset')\n",
        "\n",
        "# Download the zipped dataset\n",
        "files.download('/content/dataset_new.zip')"
      ],
      "metadata": {
        "id": "CFH9gn3JqYzF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d8b09b11-9bc9-469a-de50-83742e472998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a6081eed-2079-4d85-a559-08e07dc82469\", \"dataset_new.zip\", 188496755)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_-c_JdENdvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}